Kernelizing  the Perceptron Algorithm 
â€¢
Given ğ‘¥, predict + iff 
â€¢
On the ğ‘¡ th  mistake, update as follows: 
â€¢
Mistake on positive, set ğ‘ğ‘–ğ‘¡â†1; store ğ‘¥ğ‘–ğ‘¡ 
â€¢
Mistake on negative, ğ‘ğ‘–ğ‘¡â†âˆ’1; store ğ‘¥ğ‘–ğ‘¡ 
Perceptron ğ‘¤ğ‘¡= ğ‘ğ‘–1ğ‘¥ğ‘–1 + â‹¯+ ğ‘ğ‘–ğ‘˜ğ‘¥ğ‘–ğ‘˜ 
ğ‘¤ğ‘¡â‹…ğ‘¥= ğ‘ğ‘–1ğ‘¥ğ‘–1 â‹…ğ‘¥+ â‹¯+ ğ‘ğ‘–ğ‘˜ğ‘¥ğ‘–ğ‘˜â‹…ğ‘¥ 
X 
X 
X 
X 
X 
X 
X X 
X 
X 
O 
O 
O 
O 
O 
O 
O 
O 
w 
Exact same behavior/prediction rule as if mapped data in the 
ğœ™-space and ran Perceptron there! 
â†’ 
ğ‘ğ‘–1 ğ¾(ğ‘¥ğ‘–1, ğ‘¥) + â‹¯+ ğ‘ğ‘–ğ‘˜ğ¾(ğ‘¥ğ‘–ğ‘˜, ğ‘¥) 
Î¦-space 
ğ‘ğ‘–1 ğ¾(ğ‘¥ğ‘–1, ğ‘¥) + â‹¯+ ğ‘ğ‘–ğ‘¡âˆ’1ğ¾(ğ‘¥ğ‘–ğ‘¡âˆ’1, ğ‘¥) â‰¥0 
Do this implicitly, so computational savings!!!!! 
ğœ™(ğ‘¥ğ‘–ğ‘¡âˆ’1) â‹…ğœ™(ğ‘¥) 
