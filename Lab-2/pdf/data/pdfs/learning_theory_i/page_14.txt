Sample Complexity for Supervised Learning
Consistent Learner
â€¢
ğœ–is called error parameter
â€¢
ğ›¿is called confidence parameter
â€¢
there is a small chance the examples we get are not representative of 
the distribution
â€¢
D might place low weight on certain parts of the space
â€¢ Output: Find h in H consistent with the sample (if one exits). 
â€¢
Input: S: (x1,c*(x1)),â€¦, (xm,c*(xm))
Bound inversely linear in ğœ–
Bound only logarithmic in |H|
