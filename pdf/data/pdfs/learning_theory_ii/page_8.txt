 Sample Complexity for Supervised Learning 
Consistent Learner 
â€¢  Output: Find h in H consistent with the sample (if one exits).  
â€¢
Input: S: (x1,c*(x1)),â€¦, (xm,c*(xm)) 
So, if câˆ—âˆˆH and can find consistent fns, then only need this many 
examples to get generalization error â‰¤ğœ– with prob. â‰¥1 âˆ’ğ›¿ 
Probability over different samples of m 
training examples 
Bound only logarithmic in |H|, linear in 1/ğœ– 
