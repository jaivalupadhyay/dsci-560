Analyzing Training Error 
Theorem ğœ–ğ‘¡= 1/2 âˆ’ğ›¾ğ‘¡ (error of â„ğ‘¡ over ğ·ğ‘¡) 
ğ‘’ğ‘Ÿğ‘Ÿğ‘†ğ»ğ‘“ğ‘–ğ‘›ğ‘ğ‘™â‰¤exp  âˆ’2  ğ›¾ğ‘¡
2
ğ‘¡
 
So, if  âˆ€ğ‘¡, ğ›¾ğ‘¡â‰¥ğ›¾> 0, then ğ‘’ğ‘Ÿğ‘Ÿğ‘†ğ»ğ‘“ğ‘–ğ‘›ğ‘ğ‘™â‰¤exp  âˆ’2 ğ›¾2ğ‘‡ 
Adaboost is adaptive 
â€¢
Does not need to know ğ›¾ or T a priori 
â€¢
Can exploit  ğ›¾ğ‘¡â‰« ğ›¾ 
The training error drops exponentially in T!!! 
To get ğ‘’ğ‘Ÿğ‘Ÿğ‘†ğ»ğ‘“ğ‘–ğ‘›ğ‘ğ‘™â‰¤ğœ–, need only ğ‘‡= ğ‘‚
1
ğ›¾2 log
1
ğœ–
 rounds  
